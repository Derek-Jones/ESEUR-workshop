ESEUR Workshop - Regression modelling
=====================================
:author:    Derek M. Jones
:copyright: Somebody
:backend:   slidy
:max-width: 45em

Regression modelling
--------------------

{nbsp}

Today's hammer

{nbsp}

Fits an equation to data

* you decide which equation to fit

{nbsp}

Reasons for building a regression model

* understanding: willingness to trade-off prediction accuracy for
simplicity

* prediction: willingness to trade-off understanding for better fit

Updating from a pre-computer world
----------------------------------

image::linear_tests_cheat_sheet.png[]

Generalized linear model
------------------------

{nbsp}

<keyword>glm</keyword> a general solution

* less restrictive requirements on data characteristics
* can change default Normal to handle other error distributions

{nbsp}

Overkill for many real-life problems

* who cares, we are using a computer
* maths is more complicated than ordinary linear regression, <keyword>lm</keyword>
* uses more memory/cpu time than <keyword>lm</keyword>

Straightforward case
--------------------

.Total lines of source code in FreeBSD by days elapsed since the project started.
<<echo=FALSE,results=hide,label=Herraiz-BSD-x,fig=TRUE,align="center">>=
source("../examples/Herraiz-BSD.R")
@

rexample[examples/Herraiz-BSD.R]

Importance of domain knowledge
------------------------------

.Number of classes in the Groovy compiler at each release, in days since version 1.0.
<<echo=FALSE,results=hide,label=Groovy_change-prop2,fig=TRUE,align="center">>=
source("../examples/Groovy_change-prop2.R")
@

rexample[examples/Groovy_change-prop2.R]

How it works
------------

Linear model: simplest form of regression

<equ>\qquad y = \alpha + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon</equ>

{nbsp}

<phrase>response variable</phrase>, <equ>y</equ>, modelled as a linear combination of

* <phrase>explanatory variables</phrase>, <equ>x_n</equ> (<phrase>prediction variable</phrase> or
<phrase>predictor</phrase> are terms used when emphasizing prediction)

* additive error, <equ>\epsilon</equ>, behavior not accounted for by
explanatory variables, assumed to be independent, Normal
distribution

Linear regression
-----------------

Linear refers to the model parameters, i.e., <equ>\beta</equ>

* <equ>y = \alpha + \beta x^2 + \epsilon</equ>
* <equ>y = \alpha + \beta \log(x) + \epsilon</equ>
* <equ>y = \alpha + \beta_1 x + \beta_2 x^2 + \epsilon</equ>

{nbsp}

The most commonly used regression model

* many real world problems exhibit linear behavior, or a good enough
approximation to it for practical purposes, over their input range

* much easier to fit than non-linear models

** can usually be built with minimal input from the user
** will converge to the unique solution

Code for linear regression
--------------------------

{nbsp}

The equation:

<equ>\qquad E[\mathit{sloc}\] = \alpha + \beta\times\mathit{Number{_}days}</equ>

{nbsp}

is coded as:

[source,R]
-----
BSD_mod=glm(sloc ~ Number_days, data=bsd_info)
-----

Fitted model details
--------------------

[source,R]
-----
summary(BSD_mod)
-----

<<echo=FALSE,label=summary_linear>>=
source("../examples/summary_BSD-linear.R")
@

Fitted equation
---------------

The fitted equation is:

<equ>\qquad \mathit{sloc} = 1.139\times10^5 + 3.937\times10^2 \mathit{Number{_}days}</equ>

{nbsp}

Not a perfect fit between the model and data

* Uncertainty in the values of the model parameters:
+
<equ>\mathit{sloc}  =  (1.139\times10^5\pm1.171\times10^3) + </equ>
<equ>\qquad \qquad \qquad (3.937\times10^2\pm4.205\times10^{-1}) \mathit{Number{_}days}</equ>
////////////
<equ>\begin{eqnarray}
\mathit{sloc} & = & (1.139\times10^5\pm1.171\times10^3) + \\
              &   &   (3.937\times10^2\pm4.205\times10^{-1}) \mathit{Number{_}days}
\end{eqnarray}</equ>
////////////

* Uncertainty caused by the inability of the explanatory variable
used in the model to explain everything:
+
<equ>\mathit{sloc} = 1.139\times10^5 + 3.937\times10^2 \mathit{Number{_}days}</equ>
<equ>\qquad \qquad \qquad	       \pm4.071\times10^4</equ>
////////////
<equ>\begin{eqnarray}
\mathit{sloc} = 1.139\times10^5 & + & 3.937\times10^2 \mathit{Number{_}days} \\
				&   &    \pm4.071\times10^4
\end{eqnarray}</equ>
////////////

Predicting from a fitted model
------------------------------

{nbsp}

[source,R]
-----
BSD_pred=predict(BSD_mod)
lines(bsd_info\$Number_days, BSD_pred, col="red")

# or

BSD_pred=predict(BSD_mod,
		 newdata=list(Number_days=0:4000))

lines(0:4000, BSD_pred, col="red")
-----

The BSD data
------------

.Total lines of source code in FreeBSD by days elapsed since the project started.
<<echo=FALSE,results=hide,label=Herraiz-BSD-x,fig=TRUE,align="center">>=
source("../examples/Herraiz-BSD.R")
@

rexample[examples/Herraiz-BSD.R]

Scattered measurement points
----------------------------

.Estimated cost and duration of 73 large Dutch federal IT projects.
<<echo=FALSE,results=hide,label=federal_IT-cost_dur,fig=TRUE,align="center">>=
source("../examples/federal_IT-cost_dur.R")
@

rexample[examples/federal_IT-cost_dur.R]

Confidence intervals
--------------------

{nbsp}

What is the actual fitted model likely to be?

[source,R]
-----
fed_pred=predict(fed_mod, newdata=list(log.IT=1:7),
				se.fit=TRUE)
lines(fed_pred\$fit, col="red")

# 2.5% above and below the fit
lines(fed_pred\$fit+qnorm(0.975)*fed_pred\$se.fit,
					col="green")
lines(fed_pred\$fit+qnorm(0.025)*fed_pred\$se.fit,
					col="green")

# qnorm(0.975) == 1.96,  qnorm(0.025) == -1.96
-----

Two confidence bounds
---------------------

{nbsp}

What is the likely range of values for a new measurement?

{nbsp}

Two sources of uncertainty need to be combined

* uncertainty in the model parameters, i.e., the confidence interval

* variance in the data not explained by the fitted model

[source,R]
-----
MSE=sum(fed_mod\$residuals^2)/(length(fed_mod\$residuals)-2)

pred_se=sqrt(fed_pred\$se.fit^2+MSE)


lines(fed_pred\$fit+1.96*pred_se, col="blue")
lines(fed_pred\$fit-1.96*pred_se, col="blue")
-----

Checking visual trend
---------------------

Visual trend can be deceptive

* use local regression, <rcode>loess()</rcode>, to check visual trend

.For each distinct language, the number of lines committed on Github and the number of questions tagged with that language.
<<echo=FALSE,results=hide,label=langpop-corger-nl,fig=TRUE,align="center">>=
source("../examples/langpop-corger-nl.R")
@

rexample[examples/langpop-corger-nl.R]

Trend changes later
-------------------

.Percentage of vulnerabilities detected by developers working a given number of years in security.
<<echo=FALSE,results=hide,label=acc-sec-experience,fig=TRUE,align="center">>=
source("../examples/acc-sec-experience.R")
@

rexample[examples/acc-sec-experience.R]

Almost any data can be fitted
-----------------------------

.Number of updates and fixes in each Linux release between version 2.6.11 and 3.2.
<<echo=FALSE,results=hide,label=linux-stable,fig=TRUE,align="center">>=
source("../examples/linux-stable.R")
@

rexample[examples/linux-stable]

Updates: <keyword>summary</keyword> output
--------------------------

<rcode>Pr(&gt;|t|)</rcode> the p-value for the hypothesis that the
coefficient in the corresponding row is zero,

<<echo=FALSE,label=summary_linux-stable>>=
source("../examples/summary_linux-stable.R")
@

Nominal data
------------

Non-numeric data

* compiler flags: <code>O0</code>, <code>O2</code>, <code>O3</code>

Impact of compiler optimization flags on ability to continue
operating correctly when subject to random bit-flips

Fitted model has:

* response variable: percentage of correct benchmark program execution
* explanatory variable: optimization level as the explanatory variable

Call to <keyword>glm</keyword>

[source,R]
-----
bitflip_mod=glm(pass.masked ~ opt_level, data=bitflip)
-----

<keyword>summary</keyword> output
-------------------

<<echo=FALSE,label=comp-mask>>=
source("../examples/comp-mask.R")
@

As an equation
--------------

Fitted equation is:

<equ>\qquad \mathit{pass.masked} = 28.6 + 9.2\times \mathit{D_{O2}} + 7.4\times \mathit{D_{O3}} + 11.6\times \mathit{D_{osf}}</equ>

<equ>\mathit{D_i}</equ> is known as dummy variables or indicator variable and
has one of two values:

<equ>\qquad \qquad 1\quad\mathrm{optimization flag used} </equ>

<equ>\qquad \mathit{D_i} =</equ>

<equ>\qquad \qquad 0\quad\mathrm{optimization flag not used} </equ>
//////////
<equ>\begin{eqnarray}
  &   &1\quad\mathrm{optimization flag used}\\
D & = & \\
  &   &0\quad\mathrm{optimization flag not used}
\end{eqnarray}</equ>
//////////

<code>O0</code> value is implicit, i.e., factored into intercept: 28.6

{nbsp}

Standard errors in <code>O2</code>/<code>O3</code> large enough
for their respective <routput>Estimate</routput> coefficients to overlap

Curved data
-----------

[source,R]
-----
linux_mod=glm(sloc ~ Number_days,
					data=linux_info)
linux_mod=glm(sloc ~ Number_days+I(Number_days^2),
					data=linux_info)
-----

How much better is a fitted quadratic equation, a fitted cubic, ...?

.Lines of code in every initial release of the Linux kernel since version 1.0.
<<echo=FALSE,results=hide,label=linux-DAYLOC,fig=TRUE,align="center">>=
source("../examples/Linux-DAYLOC.R")
@

rexample[examples/Linux-DAYLOC.R]

AIC
---

Akaiki Information Criteria, <rcode>AIC()</rcode>, takes into account:

* a measure of how well a model fits the data

* free parameters have to pay their way by providing enough
improvement in a model's fit to the data

<<echo=FALSE,label=Linux-DAYLOC-AIC>>=
source("../examples/Linux-DAYLOC-AIC.R")
@

When AIC of two models differ by:

* less than 2: more or less equivalent

* between 4 and 7: clearly distinguishable

* more than 10: definitely different

Cubic model
-----------

<<echo=FALSE,label=Linux-DAYLOC-cubic>>=
source("../examples/Linux-DAYLOC-cubic.R")
@

Fitting exponential response variable
-------------------------------------

<<echo=FALSE,results=hide,label=koomeycomputertrends,fig=TRUE,align="center">>=
source("../examples/koomeycomputertrendsreleaseversion-v36.R")
@

[source,R]
-----
A_mod=glm(log(Watts) ~ Year, data=koomey)
-----

Fitted equation can be written as:

* <equ>\log(\mathit{Watts}) = \alpha + \beta \mathit{Year} + \epsilon</equ>
* <equ>\mathit{Watts} = e^{\alpha + \beta \mathit{Year} + \epsilon}</equ>
* <equ>\mathit{Watts} = e^{\alpha}\times e^{\beta \mathit{Year} \times e^{\epsilon}</equ>

rexample[examples/koomeycomputertrendsreleaseversion-v36.R]

Fitting power law response variable
-----------------------------------

<<echo=FALSE,results=hide,label=li2018_app_number,fig=TRUE,align="center">>=
source("../examples/li2018_app_number.R")
@

[source,R]
-----
A_mod=glm(log(Apps) ~ log(Releases), data=li)
A_mod=glm(log(Apps) ~ log(Releases), data=li,
				 subset=(Releases <= 20))
-----

Fitted equation can be written as:

* <equ>\log(\mathit{Apps}) = \alpha + \beta \log(\mathit{Releases}) + \epsilon</equ>
* <equ>\mathit{Apps} = e^{\alpha + \beta \log(\mathit{Releases}) + \epsilon}</equ>
* <equ>\mathit{Apps} = e^{\alpha}\times \mathit{Releases}^{\beta} \times e^{\epsilon}</equ>

rexample[examples/li2018_app_number.R]

Influential observations and Outliers
-------------------------------------

.Hours to develop software for 29 embedded consumer products and the amount of code they contain.
<<echo=FALSE,results=hide,label=lines-per-hour,fig=TRUE,align="center">>=
source("../examples/lines-per-hour.R")
@

rexample[examples/lines-per-hour.R]

Model diagnostics
-----------------

[source,R]
-----
embed_mod=glm(sloc ~ Effort, data=embedded_info)
plot(embed_mod)
-----

.Diagnostics of fitted model
<<echo=FALSE,results=hide,label=lines-hour-diagnostic,fig=TRUE,align="center">>=
source("../examples/lines-hour-diagnostic.R")
@

rexample[examples/lines-hour-diagnostic.R]

influenceIndexPlot
------------------

.<keyword>influenceIndexPlot</keyword> for the data.
<<echo=FALSE,results=hide,label=lines-hour-influence,fig=TRUE,align="center">>=
source("../examples/lines-hour-influence.R")
@

rexample[examples/lines-hour-influence.R]

Outlier or changepoint?
-----------------------

.Number of medical devices recalled by the US Food and Drug Administration, in two week bins.  Fitted straight regression line (red, with green confidence bounds) and loess fit (green).
<<echo=FALSE,results=hide,label=Alemzadeh-Recalls,fig=TRUE,align="center">>=
source("../examples/Alemzadeh-Recalls.R")
@

rexample[examples/Alemzadeh-Recalls.R]

After 2010 is different
-----------------------

.Fitted model after two observations replaced by mean value (left) and two fitted lines, one up to the end of 2010 and one after 2010.
<<echo=FALSE,results=hide,label=Alemzadeh-mininf,fig=TRUE,align="center">>=
source("../examples/Alemzadeh-mininf.R")
@

rexample[examples/Alemzadeh-mininf.R]

Data to try
-----------

Byte benchmark: byte-dos-app-benchmark.csv

* WP - word processing
* SS - spreadsheet
* Sci.Eng - scientific/engineering
* Cmplr - compiling

C source measurements: c_linelen.csv.xz

C source measurements: c_linetok.csv.xz

Project duration/effort: CSA-duration.csv.xz

Multiple regression
-------------------

{nbsp}

Multiple - more than one explanatory variable:

{nbsp}

<equ>y = \alpha + \beta_1 x_1 + \epsilon</equ>

<equ>y = \alpha + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon</equ>

<equ>y = \alpha + \beta_1 x_1 \times x_2 + \epsilon</equ>

<equ>y = \alpha + \beta_1 \log (x_1) + \beta_2 x_2 + \cdots + \beta_n \sqrt{x_n} + \epsilon</equ>

Processor & Memory speed
------------------------

.SPECint 2006 performance results for processors running at various clock rates, memory chip frequencies and processor family.
<<echo=FALSE,results=hide,label=SPEC-Mhz,fig=TRUE,align="center">>=
source("../examples/SPEC-Mhz.R")
@

rexample[examples/SPEC-Mhz.R]

More the merrier?
-----------------

{nbsp}

SPECint results contain 36 columns

R formula notation

* can specify all columns in the sample as explanatory variables

[source,R]
-----
spec_mod=glm(Result ~ ., data=cint)
-----

{nbsp}

Learn nothing

Overfitting reduces out of band prediction accuracy

Information in <rcode>Processor</rcode> column to create an almost perfect model

Just the important variables
----------------------------

80% of the variance in the data is explained by:

[source,R]
-----
spec_mod=glm(Result ~ Processor.MHz + mem_rate + mem_freq,
					        data=cint)
-----

<rcode>+</rcode> operator specifies that explanatory variables are
added

Equation fitted:

<equ>\qquad \mathit{Result}=-2.4\times 10^1+\mathit{Processor.MHz}7.3\times 10^{-3}+</equ>
<equ>\qquad \qquad \qquad \qquad \mathit{mem{_}rate}2.5\times 10^{-3} + \mathit{mem{_}freq}1.0\times 10^{-2}</equ>

//////////
<equ>\mathit{Result}=-2.4\times 10^1+\mathit{Processor.MHz}7.3\times 10^{-3}+\mathit{mem{_}rate}2.5\times 10^{-3}+\mathit{mem{_}freq}1.0\times 10^{-2}</equ>
//////////

SPEC summary output
-------------------

<<echo=FALSE,label=summary_SPEC-straight>>=
source("../R/summary_SPEC-straight.R")
@

Individual variable contribution
--------------------------------

.Individual contribution of each explanatory variable to the response variable in the fitted model of SPECint performance.
<<echo=FALSE,results=hide,label=SPEC-ind-MHz-DDR,fig=TRUE,align="center">>=
source("../examples/SPEC-ind-MHz-DDR.R")
@

[source,R]
-----
library("visreg")
...
t=visreg(spec_mod, plot=FALSE)
plot(t)
-----

rexample[examples/SPEC-ind-MHz-DDR.R]

Residuals
---------

.Residual of the fitted model of SPECint performance.
<<echo=FALSE,results=hide,label=SPEC-resid-MHz-DDR,fig=TRUE,align="center">>=
source("../examples/SPEC-resid-MHz-DDR.R")
@

rexample[examples/SPEC-resid-MHz-DDR.R]

Quadratic SPEC model
--------------------

[source,R]
-----
spec_mod=glm(Result ~ Processor.MHz + I(Processor.MHz^2)+
			mem_rate + I(mem_rate^2)+
			  mem_freq
                        , data=cint)
-----

.Individual contribution of each explanatory variable to the response variable in a quadratic model of SPECint performance.
<<echo=FALSE,results=hide,label=SPEC-quad-MHz-DDR,fig=TRUE,align="center">>=
source("../examples/SPEC-quad-MHz-DDR.R")
@

rexample[examples/SPEC-quad-MHz-DDR.R]

Updating a fitted model
-----------------------

Add/remove a new column to/from an existing model

[source,R]
-----
ecc_spec_mod=update(spec_mod, . ~ . + ecc)

ecc_spec_mod=update(spec_mod, . ~ . - mem_freq)
-----

Formula notation
----------------

.Symbols that can be used within a formula to express relationships between explanatory variables.
[label="feat-mean-var-skew", width="75%", cols="^s,<6d"]
[options="header", frame="topbot", grid="none", align="center"]
|===============================
|Operator| Effect
|+| causes both of its operands to be included in the equation.
|:| denotes an interaction between its operands, e.g., <rcode>a:b</rcode> or  <rcode>a:b:c</rcode>.
|*| denotes all possible combinations of <rcode>+</rcode> and <rcode>:</rcode> operators, e.g., <rcode>a*b</rcode> is equivalent to  <rcode>a+b+a:b</rcode>.
|^| denotes all interactions to a specific degree, e.g., <rcode>(a+b+c)^2</rcode> is equivalent to  <rcode>a+b+c+a:b+a:c+b:c</rcode>.
|.| denotes all variables in the data-frame specified in the <roption>data</roption> argument except the response variable.
|-| specifies that the right operand is removed from the equation, e.g., <rcode>a*b-a</rcode> is equivalent to  <rcode>b+a:b</rcode>.
|-1| specifies that an intercept is not to be fitted (many regression fitting functions implicitly include an intercept)
|I()| ...
|===============================

Interaction and shared contribution
-----------------------------------

.Diagram illustrating shared and non-shared contributions made by two variables in explaining Y.
<<echo=FALSE,results=hide,label=shared-contrib,fig=TRUE,align="center">>=
source("../examples/shared-contrib.R")
@

rexample[examples/shared-contrib.R]

Two models or one?
------------------

.Estimated and actual effort broken down by communication frequency, along with individually straight fitted lines.
<<echo=FALSE,results=hide,label=simula_0a,fig=TRUE,align="center">>=
source("../examples/simula_0a.R")
@

rexample[examples/simula_0a.R]

Interacting variables
---------------------

Simultaneously fit two straight lines to the data

[source,R]
-----
sim_mod=glm(Actual ~ Estimated+Estimated:Communication,
						data=sim)
-----

Fitted equation:

<equ>\qquad \mathit{Actual} = -270.1+1.18\mathit{Estimated}+0.51\mathit{Estimated}\times \mathit{D}</equ>
<equ>\qquad \qquad \qquad =  -270.1+(1.18+0.51 \mathit{D})\mathit{Estimated}</equ>

<equ>\qquad \qquad 1\quad\mathrm{daily communication} </equ>

<equ>\qquad \mathit{D} =</equ>

<equ>\qquad \qquad 0\quad\mathrm{not daily communication} </equ>

//////////
<equ>\begin{aligned}
\mathit{Actual} & = & -270.1+1.18\mathit{Estimated}+0.51\mathit{Estimated}\times D \\
                & = & -270.1+(1.18+0.51 D)\mathit{Estimated}
\end{aligned}</equ>

<equ>D = \begin{cases}1& \text{daily communication}\\0& \text{not daily communication}\end{cases}</equ>
//////////

Start complicated
-----------------

[source,R]
-----
library(MASS)

sim_mod=glm(Actual ~ (Estimated+Communication+
				Contract+Complexity)^2,
						data=sim)
simple_sim=stepAIC(sim_mod)
-----

<<echo=FALSE,label=simula_0a-Anova>>=
source("../examples/simula_0a-Anova.R")
@

After following the numbers
---------------------------

[source,R]
-----
sim_mod=glm(Actual ~ Estimated+Communication+
				Communication:Contract,
					data=sim)
-----

Fitted equation is:

<equ>\mathit{Actual} = -274.8+1.21\mathit{Estimated} + 2625\times !\mathit{D} +</equ>
<equ>\qquad \qquad \qquad \qquad \mathit{C_{fp}}(1862\times !\mathit{D} - 197.6\times \mathit{D}) +</equ>
<equ>\qquad \qquad \qquad \qquad \mathit{C_{tp}}(-2270\times !\mathit{D} - 462.2\times \mathit{D}) +</equ>
<equ>\qquad \qquad \qquad \qquad \mathit{C_{ot}}(-2298\times !\mathit{D} - 234.3\times \mathit{D})</equ>
////////////////
<equ>\begin{aligned}
\mathit{Actual} = -274.8+1.21\mathit{Estimated} + 2625\times !\mathit{D} & + & \\
					&   & \mathit{C_{fp}}(1862\times !\mathit{D} - 197.6\times \mathit{D}) + \\
					&   & \mathit{C_{tp}}(-2270\times !\mathit{D} - 462.2\times \mathit{D}) + \\
					&   & \mathit{C_{ot}}(-2298\times !\mathit{D} - 234.3\times \mathit{D})
\end{aligned}</equ>
////////////////

* <equ>\mathit{C_{fp}}</equ> 0/1 is a fixed price contract
* <equ>\mathit{C_{tp}}</equ> 0/1 is a target price contract
* <equ>\mathit{C_{ot}}</equ> 0/1 other kind of contract

Data to try
-----------

Byte benchmark: byte-dos-app-benchmark.csv

* WP - word processing
* SS - spreadsheet
* Sci.Eng - scientific/engineering
* Cmplr - compiling

Growth of PC-Lint: pclint.csv.xz

